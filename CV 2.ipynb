{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**  \n",
    "1. Explain convolutional neural network, and how does it work?**\n",
    "\n",
    "Convolutional Neural Network (CNN) is a deep learning architecture that\n",
    "is commonly used in image recognition and computer vision tasks. CNNs\n",
    "consist of convolutional layers, pooling layers, and fully connected\n",
    "layers. The convolutional layer performs feature extraction by\n",
    "convolving the input image with a set of filters to produce a feature\n",
    "map. Pooling layers reduce the size of the feature maps by\n",
    "down-sampling, and fully connected layers perform classification based\n",
    "on the extracted features.\n",
    "\n",
    "**2. How does refactoring parts of your neural network definition favor\n",
    "you?**\n",
    "\n",
    "Refactoring parts of a neural network definition can make the network\n",
    "more modular and easier to modify, improve the overall efficiency of the\n",
    "network, and help to avoid overfitting. Refactoring can involve changing\n",
    "the architecture of the network, reusing parts of the network, or\n",
    "introducing regularization techniques.\n",
    "\n",
    "**3. What does it mean to flatten? Is it necessary to include it in the\n",
    "MNIST CNN? What is the reason for this?**\n",
    "\n",
    "Flattening refers to the process of converting a multidimensional array\n",
    "or tensor into a one-dimensional array or vector. In the MNIST CNN,\n",
    "flattening is necessary because the output of the convolutional layers\n",
    "is a 3-dimensional tensor, and the fully connected layers require a\n",
    "1-dimensional input. Flattening allows the output of the convolutional\n",
    "layers to be fed into the fully connected layers for classification.\n",
    "\n",
    "**4. What exactly does NCHW stand for?**\n",
    "\n",
    "NCHW stands for \"Number of samples\", \"Number of channels\", \"Height\", and\n",
    "\"Width\", respectively. This is a data format commonly used in deep\n",
    "learning frameworks such as PyTorch and Caffe, where the input data is\n",
    "represented as a 4-dimensional tensor.\n",
    "\n",
    "**5. Why are there 7*7*(1168-16) multiplications in the MNIST CNN's\n",
    "third layer?**\n",
    "\n",
    "The third layer of the MNIST CNN has 1168 filters, each of size 7x7. The\n",
    "input to this layer is a 13x13x32 tensor, and the output is a 7x7x1168\n",
    "tensor. Therefore, there are 7x7x1168x(13x13x32) = 7x7x(1168-16)\n",
    "multiplications in this layer.\n",
    "\n",
    "**6.Explain definition of receptive field?**\n",
    "\n",
    "Receptive field refers to the region of the input image that a neuron in\n",
    "the convolutional layer is sensitive to. The receptive field of a neuron\n",
    "in a given layer is determined by the size of the filter and the stride\n",
    "of the convolutional operation in previous layers.\n",
    "\n",
    "**7. What is the scale of an activation's receptive field after two\n",
    "stride-2 convolutions? What is the reason for this?**\n",
    "\n",
    "After two stride-2 convolutions, the scale of an activation's receptive\n",
    "field is 4 times the scale of the receptive field before the\n",
    "convolutions. This is because each stride-2 convolution reduces the size\n",
    "of the feature map by a factor of 2, and the receptive field size is\n",
    "proportional to the size of the feature map.\n",
    "\n",
    "**8. What is the tensor representation of a color image?**\n",
    "\n",
    "A color image can be represented as a 3-dimensional tensor with\n",
    "dimensions (height, width, channels), where the channels represent the\n",
    "intensity of the red, green, and blue color channels.\n",
    "\n",
    "**9. How does a color input interact with a convolution?**\n",
    "\n",
    "In a convolutional layer, a color input interacts with the filters in\n",
    "the same way as a grayscale input. The filters are applied independently\n",
    "to each color channel, and the resulting feature maps are combined to\n",
    "produce the output tensor."
   ]
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
