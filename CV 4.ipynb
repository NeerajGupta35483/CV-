{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**  \n",
    "1. What is the concept of cyclical momentum?**\n",
    "\n",
    "Cyclical momentum is a technique used in optimization algorithms, where\n",
    "the momentum parameter is cycled between two values. This helps in\n",
    "faster convergence to the minima by avoiding oscillations and\n",
    "overshoots. By using cyclical momentum, the model can jump out of a\n",
    "local minima and explore other regions of the loss surface.\n",
    "\n",
    "**2. What callback keeps track of hyperparameter values (along with\n",
    "other data) during training?**\n",
    "\n",
    "The Recorder callback keeps track of hyperparameter values, losses, and\n",
    "metrics during training. It stores the data in a pandas dataframe that\n",
    "can be used for further analysis and visualization.\n",
    "\n",
    "**3. In the color dim plot, what does one column of pixels represent?**\n",
    "\n",
    "In the color dim plot, each column of pixels represents a single pixel\n",
    "in the image, with its RGB values visualized as a color. By stacking\n",
    "these columns side by side, the full color image can be visualized.\n",
    "\n",
    "**4. In color dim, what does \"poor teaching\" look like? What is the\n",
    "reason for this?**\n",
    "\n",
    "Poor teaching in color dim looks like a lack of distinction between\n",
    "different colors. This can happen when the model is not able to learn\n",
    "the complex patterns in the dataset, leading to poor generalization.\n",
    "This can be caused by several factors such as insufficient training\n",
    "data, overfitting, or inadequate model architecture.\n",
    "\n",
    "**5. Does a batch normalization layer have any trainable parameters?**\n",
    "\n",
    "Yes, a batch normalization layer has trainable parameters such as scale\n",
    "and shift parameters, which are learned during training to adjust the\n",
    "mean and variance of the batch.\n",
    "\n",
    "**6. In batch normalization during preparation, what statistics are used\n",
    "to normalize? What about during the validation process?**\n",
    "\n",
    "During training, batch normalization uses the mean and variance of the\n",
    "current batch to normalize the activations. During validation, the\n",
    "running mean and variance of the entire dataset are used.\n",
    "\n",
    "**7. Why do batch normalization layers help models generalize better?**\n",
    "\n",
    "Batch normalization layers help models generalize better by reducing the\n",
    "internal covariate shift. This means that the mean and variance of the\n",
    "activations are normalized, which helps to reduce the sensitivity of the\n",
    "model to changes in the input distribution. This improves the stability\n",
    "of the model and allows for faster convergence during training.\n",
    "\n",
    "**8.Explain between MAX POOLING and AVERAGE POOLING is number eight.**\n",
    "\n",
    "MAX POOLING and AVERAGE POOLING are two types of pooling layers used in\n",
    "CNNs. MAX POOLING returns the maximum value in a pool of values, while\n",
    "AVERAGE POOLING returns the average value. MAX POOLING is commonly used\n",
    "to extract features that are invariant to small changes in the input,\n",
    "while AVERAGE POOLING is used to reduce the dimensionality of the input.\n",
    "\n",
    "**9. What is the purpose of the POOLING LAYER?**\n",
    "\n",
    "The purpose of the POOLING LAYER is to reduce the dimensionality of the\n",
    "input while preserving the important features. It does this by\n",
    "partitioning the input into non-overlapping regions and applying a\n",
    "pooling function such as MAX or AVERAGE POOLING.\n",
    "\n",
    "**10. Why do we end up with Completely CONNECTED LAYERS?**\n",
    "\n",
    "We end up with Completely CONNECTED LAYERS to perform the final\n",
    "classification step by mapping the output of the last convolutional or\n",
    "pooling layer to a vector of class probabilities. The output of these\n",
    "layers is passed through a softmax activation function to obtain the\n",
    "final class probabilities.\n",
    "\n",
    "**11. What do you mean by PARAMETERS?**\n",
    "\n",
    "Parameters are the variables that the model learns during training, such\n",
    "as weights and biases. These variables are adjusted during training to\n",
    "minimize the loss function and improve the model's performance.\n",
    "\n",
    "**12. What formulas are used to measure these PARAMETERS?**\n",
    "\n",
    "The formulas used to measure the parameters depend on the type of layer\n",
    "and activation function used. For example, the parameters of a fully\n",
    "connected layer can be measured using the dot product between the weight\n",
    "matrix and the input vector, while the parameters of a convolutional\n",
    "layer can be measured using the convolution operation."
   ]
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
